{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91afe7b7-6629-422d-a15b-c469a8d66f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6605f012-9171-4697-aeea-27780aa3de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the environment\n",
    "# [X] reset() -> generate random environment and return a state\n",
    "# [X] random_step() -> performs a random action and returns the next_state,reward,done\n",
    "# [X] step(action) -> performs the given action and returns the next_state,reward,done\n",
    "\n",
    "class GridEnv:\n",
    "    \n",
    "    def __init__(self,rows,cols,block_prob=0.1,grid=None):\n",
    "        if grid != None:\n",
    "            self.grid = np.array(grid)\n",
    "            self.rows = len(self.grid)\n",
    "            self.cols = len(self.grid[0,:])\n",
    "            self.block_prob = None\n",
    "        else:\n",
    "            self.rows = rows\n",
    "            self.cols = cols\n",
    "            self.block_prob = block_prob\n",
    "        \n",
    "        self.observation_space = np.empty((0))\n",
    "        for i in range(self.rows * self.cols):\n",
    "            self.observation_space = np.append(self.observation_space, i)\n",
    "        \n",
    "        # Top = 0\n",
    "        # Bottom = 1\n",
    "        # Left = 2\n",
    "        # Right = 3\n",
    "        self.action_space = [0,1,2,3]\n",
    "        self.dx = [-1,0,1,0]\n",
    "        self.dy = [0,1,0,-1]\n",
    "        \n",
    "        self.uturns = 0\n",
    "        self.turns = 0\n",
    "        self.length = 0\n",
    "    \n",
    "    def random_step(self):\n",
    "        return random.choice(self.action_space)\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.block_prob != None:\n",
    "            self._generate_random_grid()\n",
    "        self.state = 0\n",
    "        self.posX = 0\n",
    "        self.posY = 0\n",
    "        self.prevAction = None\n",
    "        self.done = False\n",
    "        self.uturn = 0\n",
    "        self.turn = 0\n",
    "        self.length = 0\n",
    "        return self.state\n",
    "    \n",
    "    def step(self,action):\n",
    "        reward = 0\n",
    "        uturn_penalty = -2\n",
    "        turn_penalty = -2\n",
    "        length_penalty = -2\n",
    "        done = False\n",
    "        if action == 0:\n",
    "            # if it is over top bounds\n",
    "            if self.posX + 1 == self.rows:\n",
    "                reward = -10\n",
    "            # if there is a blocked cell\n",
    "            elif self.grid[self.posX + 1,self.posY] == 1:\n",
    "                reward = -10\n",
    "            # check for u-turn\n",
    "            elif self.prevAction == 1:\n",
    "                reward = uturn_penalty\n",
    "                self.posX += 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "                self.uturn += 1\n",
    "            # check for turns\n",
    "            elif self.prevAction == 2 or self.prevAction == 3:\n",
    "                reward = turn_penalty\n",
    "                self.posX += 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "                self.turn += 1\n",
    "            else:\n",
    "                self.posX += 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "                reward = length_penalty\n",
    "        elif action == 1:\n",
    "            # if it is below bottom bounds\n",
    "            if self.posX - 1 == -1:\n",
    "                reward = -10\n",
    "            # if there is a blocked cell\n",
    "            elif self.grid[self.posX - 1,self.posY] == 1:\n",
    "                reward = -10\n",
    "            # check for u-turn\n",
    "            elif self.prevAction == 0:\n",
    "                reward = uturn_penalty\n",
    "                self.posX -= 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "                self.uturn += 1\n",
    "            # check for turns\n",
    "            elif self.prevAction == 2 or self.prevAction == 3:\n",
    "                reward = turn_penalty\n",
    "                self.posX -= 1\n",
    "                self.turn += 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "            else:\n",
    "                self.posX -= 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "                reward = length_penalty\n",
    "        elif action == 2:\n",
    "            # if it is left of left bounds\n",
    "            if self.posY - 1 == -1:\n",
    "                reward = -10\n",
    "            # if there is a blocked cell\n",
    "            elif self.grid[self.posX,self.posY - 1] == 1:\n",
    "                reward = -10\n",
    "            # check for u-turn\n",
    "            elif self.prevAction == 3:\n",
    "                reward = uturn_penalty\n",
    "                self.posY -= 1\n",
    "                self.uturn += 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "            # check for turns\n",
    "            elif self.prevAction == 0 or self.prevAction == 1:\n",
    "                reward = turn_penalty\n",
    "                self.posY -= 1\n",
    "                self.turn += 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "            else:\n",
    "                self.posY -= 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "                reward = length_penalty\n",
    "        else:\n",
    "            # if it is right of right bounds\n",
    "            if self.posY + 1 == self.cols:\n",
    "                reward = -10\n",
    "            # if there is a blocked cell\n",
    "            elif self.grid[self.posX,self.posY + 1] == 1:\n",
    "                reward = -10\n",
    "            # check for u-turn\n",
    "            elif self.prevAction == 2:\n",
    "                reward = uturn_penalty\n",
    "                self.uturn += 1\n",
    "                self.posY += 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "            # check for turns\n",
    "            elif self.prevAction == 0 or self.prevAction == 1:\n",
    "                reward = turn_penalty\n",
    "                self.posY += 1\n",
    "                self.turn += 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "            else:\n",
    "                self.posY += 1\n",
    "                self.state = self.posX * self.rows + self.posY\n",
    "                reward = length_penalty\n",
    "                \n",
    "        if self.state == (self.rows * self.cols - 1):\n",
    "            done = True\n",
    "            \n",
    "        if reward != -10:\n",
    "            self.prevAction = action\n",
    "            self.length += 1\n",
    "        return self.state, reward, done\n",
    "        \n",
    "    def dfs(self,pos,visited):\n",
    "        if pos[0] == self.rows-1 and pos[1] == self.cols-1:\n",
    "            return True\n",
    "        visited[pos[0],pos[1]] = 1\n",
    "        found = False\n",
    "        for x,y in zip(self.dx,self.dy):\n",
    "            newX = pos[0] + x\n",
    "            newY = pos[1] + y\n",
    "            if newX < 0 or newX == self.rows or newY < 0 or newY == self.cols:\n",
    "                continue\n",
    "            elif self.grid[newX,newY] == 1:\n",
    "                continue\n",
    "            elif visited[newX,newY] == 0:\n",
    "                found |= self.dfs((newX,newY),visited)\n",
    "                if found:\n",
    "                    return True\n",
    "        return found\n",
    "        \n",
    "    def restart(self):\n",
    "        self.posX = 0\n",
    "        self.posY = 0\n",
    "        self.state = 0\n",
    "        self.prevAction = None\n",
    "        self.done = False\n",
    "        self.uturn = 0\n",
    "        self.turn = 0\n",
    "        self.length = 0\n",
    "        return self.state\n",
    "        \n",
    "    def _generate_random_grid(self):\n",
    "        done = False\n",
    "        while not done:\n",
    "            self.grid = np.zeros((self.rows,self.cols))\n",
    "            for i in range(self.rows):\n",
    "                for j in range(self.cols):\n",
    "                    if random.random() < self.block_prob:\n",
    "                        self.grid[i,j] = 1\n",
    "            self.grid[0,0] = 0\n",
    "            self.grid[self.rows-1,self.cols-1] = 0\n",
    "            \n",
    "            # DFS\n",
    "            visited = np.zeros((self.rows,self.cols))\n",
    "            start = (0,0)\n",
    "            done = self.dfs(start,visited)\n",
    "                \n",
    "    \n",
    "    def render(self):\n",
    "        for i in range(self.rows):\n",
    "            print(':',end='')\n",
    "            for j in range(self.cols):\n",
    "                if self.posX == i and self.posY == j:\n",
    "                    print('#',end=':')\n",
    "                elif (i == 0 and j == 0) or (i == self.rows-1 and j == self.cols-1):\n",
    "                    print('$',end=':')\n",
    "                elif self.grid[i,j] == 1:\n",
    "                    print('0',end=':')\n",
    "                else:\n",
    "                    print(' ',end=':')\n",
    "            print()\n",
    "            if i != self.rows-1:\n",
    "                print(' ',end='')\n",
    "                for j in range(self.cols):\n",
    "                    print('-',end=' ')\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "929fe018-45b8-48b8-b5c6-2b90bdbbb400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":#:0: : : : : :0: : :\n",
      " - - - - - - - - - - \n",
      ": : : : :0:0: :0: : :\n",
      " - - - - - - - - - - \n",
      ": :0:0: : : :0: : : :\n",
      " - - - - - - - - - - \n",
      ": : : : :0: :0: :0:0:\n",
      " - - - - - - - - - - \n",
      ": : : : : : : : :0:0:\n",
      " - - - - - - - - - - \n",
      ": :0: : : :0:0:0: : :\n",
      " - - - - - - - - - - \n",
      ": :0:0:0:0: : : : : :\n",
      " - - - - - - - - - - \n",
      ": : : : : : : : : : :\n",
      " - - - - - - - - - - \n",
      ": : :0: : : : : : : :\n",
      " - - - - - - - - - - \n",
      ": :0: : : : : : :0:$:\n"
     ]
    }
   ],
   "source": [
    "env = GridEnv(rows=10,cols=10,block_prob=0.35)\n",
    "state = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "384ff4a6-ab4b-4648-814b-eb18d9cfe13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate similar to supervised learning\n",
    "alpha = 0.198\n",
    "# parameter on how much to emphasize future gains\n",
    "gamma = 0.7\n",
    "# parameter to control exploitation/exploration\n",
    "epsilon = 0.1\n",
    "\n",
    "num_steps = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b18f710f-74ed-42b2-a737-ac9411ce683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros((len(env.observation_space), len(env.action_space)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad5b1744-eb0f-4224-9f16-854f21a71519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_steps):\n",
    "    state = env.restart()\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Choose best possible action\n",
    "        # Used epsilon to introduce exploration\n",
    "        if random.random() < epsilon:\n",
    "            action = env.random_step()\n",
    "        else:\n",
    "            action = np.argmax(q_table[state, :])\n",
    "\n",
    "        # Do the action\n",
    "        next_state, reward, done = env.step(action)\n",
    "\n",
    "        # Update q-table\n",
    "        new_q_value = (1-alpha)*q_table[state, action] + \\\n",
    "            alpha*(reward + gamma*np.max(q_table[next_state, :]))\n",
    "\n",
    "        # Assign new values and go the next state\n",
    "        q_table[state, action] = new_q_value\n",
    "        state = next_state\n",
    "        \n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f543221-ecd1-40bd-9b16-b56d7b019041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":$:0: : : : : :0: : :\n",
      " - - - - - - - - - - \n",
      ": : : : :0:0: :0: : :\n",
      " - - - - - - - - - - \n",
      ": :0:0: : : :0: : : :\n",
      " - - - - - - - - - - \n",
      ": : : : :0: :0: :0:0:\n",
      " - - - - - - - - - - \n",
      ": : : : : : : : :0:0:\n",
      " - - - - - - - - - - \n",
      ": :0: : : :0:0:0: : :\n",
      " - - - - - - - - - - \n",
      ": :0:0:0:0: : : : : :\n",
      " - - - - - - - - - - \n",
      ": : : : : : : : : : :\n",
      " - - - - - - - - - - \n",
      ": : :0: : : : : : : :\n",
      " - - - - - - - - - - \n",
      ": :0: : : : : : :0:#:\n",
      "Total penalty => 0\n",
      "Steps => 18\n",
      "Turns => 4\n",
      "U-turns => 0\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "state = env.restart()\n",
    "total_penalty = 0\n",
    "\n",
    "while not done:\n",
    "    clear_output(wait=True)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    action = np.argmax(q_table[state,:])\n",
    "    next_state,reward,done = env.step(action)\n",
    "    \n",
    "    if reward == -10:\n",
    "        total_penalty += 1\n",
    "    state = next_state\n",
    "    env.render()\n",
    "    \n",
    "print(f\"Total penalty => {total_penalty}\\nSteps => {env.length}\\nTurns => {env.turn}\\nU-turns => {env.uturn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016148ac-bd1d-48d8-9383-46e1e552490a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
